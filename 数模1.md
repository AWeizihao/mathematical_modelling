# 传统算法 2: 图论算法
## 最大权问题——匈牙利算法
### 算法调用
首先，匈牙利算法被封装为一个networkX的子函数（python）：
```python
nx.algorithms.matching.max_weight_matching(G, maxcardinality=True)
```
在matlab中，也可以:
```
% 创建一个二分图的邻接矩阵
A = [0 1 1;
     1 0 0;
     0 0 1];

% 使用bipartite_matching函数来找最大匹配
[matching, card] = bipartite_matching(A);
```

这意味着我们只需要会调用，而对其实现仅做了解。下面的内容给出算法的原理。

匈牙利算法用于解决**最大权问题**。在开始介绍最大权问题前，我们先简单介绍二分图。

在图论中，“图”由“边”和边的交点即“节点”组成，二叉树就是一个图。而二分图，顾名思义，是指这个图可以分为两半。严格来说，它要求这两半互不相交，且图中每条边连接的两个点都属于不同的区域。如下图就是一个二分图。

![](img/image.png)

### 匹配
匹配就是一种配对，即左边部分的元素与右边部分的元素相配对，且这种配对要求1对1的配对。

满足这种匹配条件的边，称为匹配边。不满足的就是非匹配边。被匹配的点称匹配点。显然，对于一个确定的图，并不一定能保证全图所有点所有边都能被匹配。我们要找匹配率最高的那种情况，即最大匹配。

### 最大权问题
现在我们可以着手最大权问题。

给定一个二分图 $G = (U, V, E)$，其中 $U$ 和 $V$ 是节点集合，$E$ 是边集。每条边 $(u, v) \in E$, 其中 $u \in U$ 和 $v \in V$，连接点u和点v，并且有一个相关的权重 $w(u, v)$。

最大权匹配问题要求找到一个匹配 $M \subseteq E$，使得匹配的权重总和$$∑w(u,v)$$最大。

按照定义，我们要找的那个匹配一定是这个图的子图，即从图中的点和边中选择其中的几条，而不能自己创造边。

为了讲述算法，我们要引入下面的概念：

### 交替路
从一个未匹配点出发，依次经过 非匹配边、匹配边、非匹配边… 形成的路径。注意交替的是边而不是点。如下图，我们创建一个匹配，即1-6、4-8的两个配对组成一个的匹配（红色）。那么下面就是一个交替路。

![Alt text](img/image-2.png)
![Alt text](img/image-3.png)

### 增广路
从一个未匹配点出发，走交替路，若途径另一未匹配点（除起点外），则这条交替路称为增广路。上图也是一个增广路。

而增广路有一个很有用的性质：**路 P 的非匹配总边比匹配边多一条**。

这也意味着，经过取反操作（即把上图红色和黑色互换，黑色视为匹配）可以得到一个更大的匹配（匹配边+1）。故可以通过不停地找增广路来增加匹配中的匹配边和匹配点。

当一个匹配方法不能再被增广，即不能找出一个增广路包含这个匹配，说明这个匹配是最大匹配。这就是匈牙利算法。


至此就是匈牙利算法需要的全部图论知识。

### 匈牙利算法
匈牙利树一般由 DFS （深度优先搜索）构造，其是从一个未匹配点出发，走交替路，直到另一个未匹配点结束（即一个增广路）。

![Alt text](img/image-1.png)
```
开始时，每个节点都未被匹配。

对于图中左侧的每个节点u：
    设置标号lx[u]为节点u所有出边的最大权重。
    设置标号ly[u]为0。

重复以下步骤直到所有节点都被匹配：
    选择一个未匹配的左侧节点u。
    使用广度优先搜索（BFS）从u开始，尝试找到一条增广路径。
    如果找不到增广路径：
        更新lx和ly的值来允许找到新的增广路径。
    如果找到了增广路径：
        更新匹配，将路径上的边加入匹配集合。
    重复这个过程。

完成后，返回所有的匹配。
```

由于不对标算法竞赛，自己写一个匈牙利算法没有任何意义。python庞大的开源社区可以为我们所用，我们只需要导入python的图论库`networkX`，即可调用已被封装为函数的匈牙利算法。

```python
import networkX as nx
# 创建一个无向图
G = nx.Graph()

# 添加边和权重示例
G.add_edge('A', '1', weight=3)
G.add_edge('A', '2', weight=2)
G.add_edge('B', '1', weight=1)
G.add_edge('B', '2', weight=3)
G.add_edge('C', '3', weight=5)

# 使用匈牙利算法寻找最大权匹配
max_match = nx.algorithms.matching.max_weight_matching(G, maxcardinality=True)

print(max_match)
```


严格来说，我们介绍的算法是KM算法，即Kuhn-Munkres算法，也被称为改进的匈牙利算法。

最简单的匈牙利算法的一个显而易见的应用是，对于M个求职者和N个职业，每个求职者有自己的几个心仪的职业，如何一对一地分配职业使得每个人都满意。这里的“心仪”就是一种只有布尔值的权。而KM算法允许更复杂的权值。

而networkx里的`algorithms.matching.max_weight_matching`能很好实现KM算法的功能。

## 旅行商问题（Travelling Salesman Problem）——TSP算法
TSP全称为Travelling Salesman Problem（旅行商问题），通俗而言，它是指对于给定的一系列城市和每对城市之间的距离，找到访问每一座城市仅一次并回到起始城市的最短回路。

TSP问题在运筹学发展史上有重要的意义，1952年，Danzig, Fulkerson和Johnson成功的解决了美国本土分数不同州的48个城市和哥伦比亚特区共49个城市的TSP实例，使更多的人初次了解了组合优化研究的意义，也感受到了离散问题求解的准度。

因为TSP是（著名的）NP问题，即超多项式问题，随着规模的增加，求解最优解所需的时间是爆炸式的指数增长。

BTW，我们可以简单介绍时间复杂度。对于一个问题，我们最多嵌套使用了p层次数为n的循环，时间复杂度就表示为$O(n^p)$。这里我们默认n是非常大的，因此一个算法内有许多嵌套循环的时候，我们只关心最深的那个：$$O(n^p+n^{p-1}+...+n)=O(n^p)$$同时，这里也不关心系数而只关心数量级。

作为一个估计，对于一些简单问题，$O(n^2)$一般是能容忍的最大的复杂度；$O(n!)$和$O(m^n)$这种复杂度的算法，一般被视为不可用，因为对于规模极其敏感，不仅慢而且容易内存溢出。

利用复杂度，我们可以感受算法的力量：对于查找问题，如果使用枚举查找，复杂度是$O(n)$，而二分法的复杂度是$O(\log n)$（因为每次循环次数都是上一次是1/2）。

*****
TSP问题的算法很多，其中最简单的就是**动态规划**和**贪心算法**（当然，枚举法是最简单也最烂的，复杂度达$O(n!)$），然而这两个算法一个用时长，一个准确度低。还有很多经过优化的启发式算法，例如蚁群算法、遗传算法、模拟退火算法，他们一方面不保证解的精度和收敛，另一方面也不见得很快。

对于简单的问题，我们将介绍LKU算法，这是一种高度优化的算法，在大规模实例中表现非常好；对于超大规模的TSP问题，我们将介绍机器学习。

LKU算法有现成的求解器。
下载地址：http://akira.ruc.dk/~keld/research/LKH-3

代码中包括DOC文档， SRC源代码，以及样例数据（pr2392, whizzkids96），以及参数文件par：
```
PROBLEM_FILE = pr2392.tsp
#OPTIMUM = 378032
#MOVE_TYPE = 5
#PATCHING_C = 3
#PATCHING_A = 2
#RUNS = 10
```
在par文件中加一行`TOUR_FILE = ./output.txt`，可以输出最优路径。

也可以直接在python中调用它，但是需要使用接口，并非直接的代码。作者在doc文件夹中给出了数据集TSPLIB的格式。

在windows中详细的操作见https://zhuanlan.zhihu.com/p/443385104